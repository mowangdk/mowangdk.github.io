---
layout: post
title:  "weekly report"
date:   2022-12-03 22:30:08 +0800
categories: weeklyreport
---


# 读书

### 闪客的操作系统源码分析

这两周在家工作, 基本上没投入了, 时间全部放在工作上了. 这么想想还是上班好一些(不容易偷懒

### 大话存储

#### 磁盘控制器和驱动器控制电路
- 磁盘控制器
  部署在南桥上的, 主要负责从操作系统接受 SCSI/ATA 指令集,  翻译成 SCSI/ATA 裸指令集. 然后发送给磁盘上的驱动控制电路, 同样, 磁盘控制器也负责各个磁盘的选主之类的管理工作
- 驱动器控制电路
  这个是跟着磁盘走的, 将从 SCSI/IDE 线缆传递过来的 SCSI/ATA 指令集翻译成磁盘运动的指令指挥磁盘进行机械性运动

#### IOPS 和它的小伙伴们

IO latency 主要指的是命令从 磁盘控制器上下发, 到收到请求结果之后这一段时间, 不过由于从 CPU 下发 SCSI/ATA 指令到磁盘控制器基本上不会有什么问题 & 耗时, 所以从代码中的命令下发也不会有什么问题. 一般在 20ms 之下就算可以接受, 空闲情况下 IO lantency 可以在 1ms 及以下.

就算 IO lantancy 在 1ms, 那么我们可以得出 IOPS 最多也不过在 1000(1000ms/1ms) 左右, 那么现在号称 几十万,几百万的 IOPS 是如何得到的?

Queue Depth 就是上面问题的答案, 我们每条命令都不是独立发送的, 而是将多条命令聚合到一起之后批量发送, 目标设备自动执行 IO. 批量指令的最大条目数, 就是由 Queue Depth 决定.

这三者的基本公式是: IOPS = (Queue Depth)/(IO lantancy). 一旦 io 增加到处理器的最大处理能力, 之后 iops 的增长慢慢趋缓, 而 IO lantancy 则会陡然增加

IOPS的性能表现
- 每次写入很大的数据 + 频繁换道 IOPS 基本上最低
- 每次写入很小的数据 + 不频繁换道 IOPS 可以达到很高的数值
- 每次 IO 写入很大的连续数据, 同样 IOPS 很低

> 写入 10000 个大小为 1KB 的文件到磁盘上比写入一个 10MB 大小的文件要多得多, 虽然数据总量一样, 但是文件越多, 意味着底层可能要做几万甚至十几万次 IO 才能完成, 而写入一个 10MB 的大文件只需要几十个 IO 就可以完成, 前者需要的是提供很大 IOPS 的磁盘, 后者反而需要较大传输带宽的磁盘

#### 串行和并行

我们传统观念上,并行在大多数情况下是一定会比串行要快的, 但是这个在磁盘领域并不通用. 反而串行是占优势的一方. 现在硬盘的外设接口基本上已经彻底被串行传输占领. 主要原因是因为并行接口无法提高频率, 一旦提高频率, 在电路高速震荡的时候, 数据线之间就会产生巨大的感染, 即使加了屏蔽线也无法保证很高的传输频率.所以说,并行的传输速率高,但是效率慢, 串行的传输数率低, 但是效率高. 整体上来看,还是串行的性能要高;.



# 工作

- 拔盘失败问题
  最近一直出现挂盘失败的问题, 现象是挂载了数据盘之后宿主机上没有办法看到设备符. 但是对应的盘符在管控端看到却是正常的. 遇到这种问题首先需要看
  挂盘时刻的 dmesg 日志, 结果发现, 在 pci 发出挂盘中断的时候, 突然被在同一个端口发出的一个卸盘中断给 cancel 了, 导致盘没有挂载, 在继续排查
  发现这个卸盘中断是由上个挂载在同一个端口的云盘发出的. 原因是因为端口发出的卸盘动作 os 没有完成,超时了, 导致卸盘动作在同一个端口进行了重发.目前
  对于为什么磁盘卸载会超时这个情况没有说明.需要进一步探究原因 

> 排查之后发现 dmesg 出现了如下错误 BAR 14: no space for xxx, 跟内核同学确认了这个并没有太大问题, 只要最后挂载成功了就算是普通报错


- 组件升级失败
  发现 ds 组件在 apply 升级经常会遇到失败的问题, 原因是有节点是 notready 的, 之前记得 openkruise 有兼容过这个问题, 但是试了一下发现依旧不行.
  确认了下是新版把这个功能去掉了. 结果目前想要过滤掉这些 notready 的节点只能通过设置 maxunavailable 的配置了 